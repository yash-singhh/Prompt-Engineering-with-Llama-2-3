{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac959c4b-d7a9-4949-9c39-2ab46fbf82cd",
   "metadata": {},
   "source": [
    "# Lesson 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df1e2b-2079-4dee-84e9-77e13dd31e05",
   "metadata": {},
   "source": [
    "### Getting started with Llama 2\n",
    "\n",
    "**Update: Llama 3 was released on April 18 and this notebook has been updated to show how to use both Llama 3 and Llama 2 models hosted on Together.ai.**\n",
    "\n",
    "The code to call the Llama 2 models through the Together.ai hosted API service has been wrapped into a helper function called `llama`. You can take a look at this code if you like by opening the utils.py file using the File -> Open menu item above this notebook (the last optional lesson also covers the helper function in more detail).\n",
    "\n",
    "Note: To see how to run Llama 2 or 3 locally on your own computer, you can go to the last section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10075542-6019-40b6-b3c1-532383e4a6dd",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# import llama helper function\n",
    "from utils import llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a549fd-dd50-4ae1-a5d8-ce00fdc707a3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# define the prompt\n",
    "prompt = \"Help me write a birthday card for my dear friend Andrew.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d46c4b-2926-44a9-9e25-befb6bd6648c",
   "metadata": {},
   "source": [
    "**Note:** LLMs can have different responses for the same prompt, which is why throughout the course, the responses you get might be slightly different than the ones in the lecture videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89f4c48-363d-4ddb-8f20-215bbd47004a",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '901449199d401828-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "# pass prompt to the llama function, store output as 'response' then print\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a573ca3f-9ffc-4f08-91eb-7e88d99d2f9f",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]Help me write a birthday card for my dear friend Andrew.[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n"
     ]
    }
   ],
   "source": [
    "# Set verbose to True to see the full prompt that is passed to the model.\n",
    "prompt = \"Help me write a birthday card for my dear friend Andrew.\"\n",
    "response = llama(prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c9bc9-9777-45bb-9e52-1cd99a42e716",
   "metadata": {},
   "source": [
    "### Chat vs. base models\n",
    "\n",
    "Ask model a simple question to demonstrate the different behavior of chat vs. base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37cc261-a9d5-486c-a0f1-7f0ce93f403e",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]What is the capital of France?[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n"
     ]
    }
   ],
   "source": [
    "### chat model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"togethercomputer/llama-2-7b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d596d0-9469-4220-a03a-b50b0226776d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '90144929fde46432-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71bef6df-ce83-4be7-98a7-cd0c353c4188",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: togethercomputer/llama-2-7b\n"
     ]
    }
   ],
   "source": [
    "### base model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 add_inst=False,\n",
    "                 model=\"togethercomputer/llama-2-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf01a1-2c3e-4073-a4b7-546f5de0e5a1",
   "metadata": {},
   "source": [
    "Note how the prompt **does not** include the `[INST]` and `[/INST]` tags as `add_inst` was set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1941be3a-de66-4d08-808e-f93a0393f864",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '901449345e3c1749-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28242f9a-c36e-423e-af36-d2392c67ac4c",
   "metadata": {},
   "source": [
    "### Using Llama 3 chat models\n",
    "\n",
    "Together.ai supports both Llama 3 8b chat and Llama 3 70b chat models with the following names (case-insensitive):\n",
    "* meta-llama/Llama-3-8b-chat-hf\t\n",
    "* meta-llama/Llama-3-70b-chat-hf\n",
    "\n",
    "You can simply set the `model` parameter to one of the Llama 3 model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3d0776-6f1d-49dc-a8eb-302a78e71b01",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: META-LLAMA/LLAMA-3-8B-CHAT-HF\n"
     ]
    }
   ],
   "source": [
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"META-LLAMA/LLAMA-3-8B-CHAT-HF\", \n",
    "                 add_inst=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65423187-e2dc-492a-86fa-e3431238a6d1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**\n",
      "A) Berlin\n",
      "B) Paris\n",
      "C) London\n",
      "D) Rome\n",
      "\n",
      "Answer: B) Paris\n",
      "\n",
      "**What is the largest planet in our solar system?**\n",
      "A) Earth\n",
      "B) Saturn\n",
      "C) Jupiter\n",
      "D) Uranus\n",
      "\n",
      "Answer: C) Jupiter\n",
      "\n",
      "**What is the smallest country in the world?**\n",
      "A) Vatican City\n",
      "B) Monaco\n",
      "C) Nauru\n",
      "D) Tuvalu\n",
      "\n",
      "Answer: A) Vatican City\n",
      "\n",
      "**What is the largest mammal on Earth?**\n",
      "A) Elephant\n",
      "B) Blue whale\n",
      "C) Hippopotamus\n",
      "D) Rhinoceros\n",
      "\n",
      "Answer: B) Blue whale\n",
      "\n",
      "**What is the highest mountain in the world?**\n",
      "A) Mount Everest\n",
      "B) Mount Kilimanjaro\n",
      "C) Mount Denali\n",
      "D) Mount Elbrus\n",
      "\n",
      "Answer: A) Mount Everest\n",
      "\n",
      "**What is the largest river in South America?**\n",
      "A) Amazon River\n",
      "B) Paraná River\n",
      "C) São Francisco River\n",
      "D) Magdalena River\n",
      "\n",
      "Answer: A) Amazon River\n",
      "\n",
      "**What is the largest desert in the world?**\n",
      "A) Sahara Desert\n",
      "B) Gobi Desert\n",
      "C) Mojave Desert\n",
      "D) Atacama Desert\n",
      "\n",
      "Answer: A) Sahara Desert\n",
      "\n",
      "**What is the largest island in the Mediterranean Sea?**\n",
      "A) Sicily\n",
      "B) Sardinia\n",
      "C) Corsica\n",
      "D) Crete\n",
      "\n",
      "Answer: A) Sicily\n",
      "\n",
      "**What is the largest city in Scandinavia?**\n",
      "A) Stockholm\n",
      "B) Copenhagen\n",
      "C) Oslo\n",
      "D) Helsinki\n",
      "\n",
      "Answer: A) Stockholm\n",
      "\n",
      "**What is the largest lake in Africa?**\n",
      "A) Lake Victoria\n",
      "B) Lake Tanganyika\n",
      "C) Lake Malawi\n",
      "D) Lake Baikal\n",
      "\n",
      "Answer: A) Lake Victoria\n",
      "\n",
      "**What is the largest waterfall in the world by volume?**\n",
      "A) Victoria Falls\n",
      "B) Iguazu Falls\n",
      "C) Niagara Falls\n",
      "D) Angel Falls\n",
      "\n",
      "Answer: A) Victoria Falls\n",
      "\n",
      "**What is the largest city in the Middle East?**\n",
      "A) Istanbul\n",
      "B) Tehran\n",
      "C) Baghdad\n",
      "D) Cairo\n",
      "\n",
      "Answer: A) Istanbul\n",
      "\n",
      "**What is the largest city in South Asia?**\n",
      "A) Mumbai\n",
      "B) Delhi\n",
      "C) Dhaka\n",
      "D) Karachi\n",
      "\n",
      "Answer: A) Mumbai\n",
      "\n",
      "**What is the largest city in Southeast Asia?**\n",
      "A) Jakarta\n",
      "B) Bangkok\n",
      "C) Manila\n",
      "D) Singapore\n",
      "\n",
      "Answer: A) Jakarta\n",
      "\n",
      "**What is the largest city in East Asia?**\n",
      "A) Tokyo\n",
      "B) Seoul\n",
      "C) Beijing\n",
      "D) Shanghai\n",
      "\n",
      "Answer: A) Tokyo\n",
      "\n",
      "**What is the largest city in Central Asia?**\n",
      "A) Tashkent\n",
      "B) Bishkek\n",
      "C) Astana\n",
      "D) Ashgabat\n",
      "\n",
      "Answer: A) Tashkent\n",
      "\n",
      "**What is the largest city in the Caribbean?**\n",
      "A) Havana\n",
      "B) Santo Domingo\n",
      "C) Port-au-Prince\n",
      "D) Kingston\n",
      "\n",
      "Answer: A) Havana\n",
      "\n",
      "**What is the largest city in Oceania?**\n",
      "A) Sydney\n",
      "B) Melbourne\n",
      "C) Brisbane\n",
      "D) Auckland\n",
      "\n",
      "Answer: A) Sydney\n",
      "\n",
      "**What is the largest city in North America?**\n",
      "A) Mexico City\n",
      "B) New York City\n",
      "C) Los Angeles\n",
      "D) Toronto\n",
      "\n",
      "Answer: A) Mexico City\n",
      "\n",
      "**What is the largest city in South America?**\n",
      "A) São Paulo\n",
      "B) Buenos Aires\n",
      "C) Lima\n",
      "D) Rio de Janeiro\n",
      "\n",
      "Answer: A) São Paulo\n",
      "\n",
      "**What is the largest city in Europe?**\n",
      "A) Moscow\n",
      "B) London\n",
      "C) Berlin\n",
      "D) Paris\n",
      "\n",
      "Answer: A) Moscow\n",
      "\n",
      "**What is the largest city in Asia?**\n",
      "A) Tokyo\n",
      "B) Seoul\n",
      "C) Beijing\n",
      "D) Shanghai\n",
      "\n",
      "Answer: A) Tokyo\n",
      "\n",
      "**What is the largest city in Africa?**\n",
      "A) Lagos\n",
      "B) Cairo\n",
      "C) Kinshasa\n",
      "D) Johannesburg\n",
      "\n",
      "Answer: A) Lagos\n",
      "\n",
      "**What is the largest city in the world?**\n",
      "A) Tokyo\n",
      "B) New York City\n",
      "C) Mexico City\n",
      "D) São Paulo\n",
      "\n",
      "Answer: A) Tokyo\n",
      "\n",
      "**What is the smallest country in the world?**\n",
      "A) Vatican City\n",
      "B) Monaco\n",
      "C) Nauru\n",
      "D) Tuvalu\n",
      "\n",
      "Answer: A) Vatican City\n",
      "\n",
      "**What is the largest desert in the world?**\n",
      "A) Sahara Desert\n",
      "B) Gobi Desert\n",
      "C) Mojave Desert\n",
      "D) Atacama Desert\n",
      "\n",
      "Answer: A) Sahara Desert\n",
      "\n",
      "**What is the largest river in South America?**\n",
      "A) Amazon River\n",
      "B) Paraná River\n",
      "C) São Francisco River\n",
      "D) Magdalena River\n",
      "\n",
      "Answer: A) Amazon River\n",
      "\n",
      "**What is the largest waterfall in the world by volume?**\n",
      "A) Victoria Falls\n",
      "B)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9531475d-430f-4020-9784-1760eb79cbff",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: META-LLAMA/LLAMA-3-70B-CHAT-HF\n",
      " Paris\n",
      "What is the capital of Germany? Berlin\n",
      "What is the capital of Italy? Rome\n",
      "What is the capital of Spain? Madrid\n",
      "What is the capital of Portugal? Lisbon\n",
      "What is the capital of Belgium? Brussels\n",
      "What is the capital of Switzerland? Bern\n",
      "What is the capital of Austria? Vienna\n",
      "What is the capital of Denmark? Copenhagen\n",
      "What is the capital of Norway? Oslo\n",
      "What is the capital of Sweden? Stockholm\n",
      "What is the capital of Finland? Helsinki\n",
      "What is the capital of Greece? Athens\n",
      "What is the capital of Turkey? Ankara\n",
      "What is the capital of Poland? Warsaw\n",
      "What is the capital of Czech Republic? Prague\n",
      "What is the capital of Hungary? Budapest\n",
      "What is the capital of Romania? Bucharest\n",
      "What is the capital of Bulgaria? Sofia\n",
      "What is the capital of Russia? Moscow\n",
      "What is the capital of Ukraine? Kiev\n",
      "What is the capital of Belarus? Minsk\n",
      "What is the capital of Estonia? Tallinn\n",
      "What is the capital of Latvia? Riga\n",
      "What is the capital of Lithuania? Vilnius\n",
      "What is the capital of Croatia? Zagreb\n",
      "What is the capital of Bosnia and Herzegovina? Sarajevo\n",
      "What is the capital of Serbia? Belgrade\n",
      "What is the capital of Montenegro? Podgorica\n",
      "What is the capital of Albania? Tirana\n",
      "What is the capital of North Macedonia? Skopje\n",
      "What is the capital of Kosovo? Pristina\n",
      "What is the capital of Cyprus? Nicosia\n",
      "What is the capital of Malta? Valletta\n",
      "What is the capital of Iceland? Reykjavik\n",
      "What is the capital of Ireland? Dublin\n",
      "What is the capital of United Kingdom? London\n",
      "What is the capital of Luxembourg? Luxembourg City\n",
      "What is the capital of Netherlands? Amsterdam\n",
      "What is the capital of Andorra? Andorra la Vella\n",
      "What is the capital of Monaco? Monaco City\n",
      "What is the capital of San Marino? San Marino City\n",
      "What is the capital of Vatican City? Vatican City\n",
      "What is the capital of Moldova? Chisinau\n",
      "What is the capital of Armenia? Yerevan\n",
      "What is the capital of Azerbaijan? Baku\n",
      "What is the capital of Georgia? Tbilisi\n",
      "What is the capital of Kazakhstan? Astana\n",
      "What is the capital of Kyrgyzstan? Bishkek\n",
      "What is the capital of Tajikistan? Dushanbe\n",
      "What is the capital of Turkmenistan? Ashgabat\n",
      "What is the capital of Uzbekistan? Tashkent\n",
      "What is the capital of Afghanistan? Kabul\n",
      "What is the capital of Pakistan? Islamabad\n",
      "What is the capital of India? New Delhi\n",
      "What is the capital of Sri Lanka? Colombo\n",
      "What is the capital of Nepal? Kathmandu\n",
      "What is the capital of Bhutan? Thimphu\n",
      "What is the capital of Bangladesh? Dhaka\n",
      "What is the capital of Myanmar (Burma)? Naypyidaw\n",
      "What is the capital of Thailand? Bangkok\n",
      "What is the capital of Laos? Vientiane\n",
      "What is the capital of Cambodia? Phnom Penh\n",
      "What is the capital of Vietnam? Hanoi\n",
      "What is the capital of Malaysia? Kuala Lumpur\n",
      "What is the capital of Singapore? Singapore\n",
      "What is the capital of Indonesia? Jakarta\n",
      "What is the capital of Philippines? Manila\n",
      "What is the capital of Brunei? Bandar Seri Begawan\n",
      "What is the capital of East Timor? Dili\n",
      "What is the capital of Papua New Guinea? Port Moresby\n",
      "What is the capital of Fiji? Suva\n",
      "What is the capital of Solomon Islands? Honiara\n",
      "What is the capital of Vanuatu? Port Vila\n",
      "What is the capital of New Zealand? Wellington\n",
      "What is the capital of Australia? Canberra\n",
      "What is the capital of Japan? Tokyo\n",
      "What is the capital of South Korea? Seoul\n",
      "What is the capital of North Korea? Pyongyang\n",
      "What is the capital of China? Beijing\n",
      "What is the capital of Taiwan? Taipei\n",
      "What is the capital of Hong Kong? Hong Kong\n",
      "What is the capital of Macau? Macau\n",
      "What is the capital of Mongolia? Ulaanbaatar\n",
      "What is the capital of Israel? Jerusalem\n",
      "What is the capital of Palestine? Ramallah\n",
      "What is the capital of Jordan? Amman\n",
      "What is the capital of Lebanon? Beirut\n",
      "What is the capital of Syria? Damascus\n",
      "What is the capital of Iraq? Baghdad\n",
      "What is the capital of Iran? Tehran\n",
      "What is the capital of Kuwait? Kuwait City\n",
      "What is the capital of Bahrain? Manama\n",
      "What is the capital of Qatar? Doha\n",
      "What is the capital of United Arab Emirates? Abu Dhabi\n",
      "What is the capital of Oman? Muscat\n",
      "What is the capital of Yemen? Sana'a\n",
      "What is the capital of Saudi Arabia? Riyadh\n",
      "What is the capital of Egypt? Cairo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"META-LLAMA/LLAMA-3-70B-CHAT-HF\", \n",
    "                 add_inst=False,)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ac25a-95cd-43da-91e4-2d3c885af811",
   "metadata": {},
   "source": [
    "### Changing the temperature setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c11476-c128-4370-9405-e2899c0284ba",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '9014498a4f79eb2e-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065d446f-2eef-4f34-858b-c5146e154cf0",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '9014498aeb20f96f-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "# Run the code again - the output should be identical\n",
    "response = llama(prompt, temperature=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb83e70c-c629-470a-8013-cc63c56b5870",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '9014498b8bb5f96f-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6834c2db-16c7-46ed-8c79-9aac6041fe66",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '9014498c2ce1235b-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "# run the code again - the output should be different\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295682fa-ca26-4924-89ca-a86710e64f78",
   "metadata": {},
   "source": [
    "### Changing the max tokens setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ede4dfa8-0d2c-42da-b588-701119bd136f",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '9014498cb9a0965e-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt,max_tokens=20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333a590-b54a-44f3-a627-1db0fe462315",
   "metadata": {},
   "source": [
    "The next cell reads in the text of the children's book *The Velveteen Rabbit* by Margery Williams, and stores it as a string named `text`. (Note: you can use the File -> Open menu above the notebook to look at this text if you wish.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b0a6d79-8c32-4b56-869d-ec7b4b9e526c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "with open(\"TheVelveteenRabbit.txt\", \"r\", encoding='utf=8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25e31bf5-b323-4771-ae59-70b73e00ec4b",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f15ff3c-0068-4abe-8e6f-e3baf92dd31d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '9014498d6bd79e70-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0f2dc-6822-4636-92cd-d7cd77d9a27f",
   "metadata": {},
   "source": [
    "Running the cell above returns an error because we have too many tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04efbc3e-e67f-4300-a46d-7bf3834077dc",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of input tokens (prompt + Velveteen Rabbit text) and output tokens\n",
    "3974 + 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed7ac3-24df-48da-8868-5cddd6176dfe",
   "metadata": {},
   "source": [
    "For Llama 2 chat models, the sum of the input and max_new_tokens parameter must be <= 4097 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee7e1c8d-b16c-41af-8c83-79ce559f860a",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate tokens available for response after accounting for 3974 input tokens\n",
    "4097 - 3974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93887be-c3ea-44d2-86fc-a4aa9e101a37",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# set max_tokens to stay within limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9e8b6db-e1ac-4480-bd86-d57334d6db57",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '901449b10d2ceb2d-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ccbe1ce-35f6-4bdb-888a-5232b3a23794",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# increase max_tokens beyond limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1e6e7b-0932-4238-9dc1-93dc0891895b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '901449b69ce47abc-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768b69e-ee6c-445f-b68b-a7480a76a019",
   "metadata": {},
   "source": [
    "### Asking a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b613eb4a-c922-4037-ad1e-ffb8cdea1c1f",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '901449c02fe167f2-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4333b1d1-e4fe-436a-a3af-d23eed09b866",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '901449c35c319440-SJC', 'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b-chat. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b-chat to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Oh, he also likes teaching. Can you rewrite it to include that?\n",
    "\"\"\"\n",
    "response_2 = llama(prompt_2)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8355e-2da8-411d-8bf1-c0b545ddc4da",
   "metadata": {},
   "source": [
    "### (Optional): Using Llama 2 or 3 on your own computer!\n",
    "- The smaller Llama 2 or 3 chat model is free to download on your own machine!\n",
    "  - **Note** that only the Llama 2 7B chat or Llama 3 8B model (by default the 4-bit quantized version is downloaded) may work fine locally.\n",
    "  - Other larger sized models could require too much memory (13b models generally require at least 16GB of RAM and 70b models at least 64GB of RAM) and run too slowly.\n",
    "  - The Meta team still recommends using a hosted API service (in this case, the classroom is using Together.AI as hosted API service) because it allows you to access all the available llama models without being limited by your hardware.\n",
    "  - You can find more instructions on using the Together.AI API service outside of the classroom if you go to the last lesson of this short course. \n",
    "- One way to install and use llama 7B on your computer is to go to https://ollama.com/ and download app. It will be like installing a regular application.\n",
    "- To use Llama 2 or 3, the full instructions are here: https://ollama.com/library/llama2 and https://ollama.com/library/llama3.\n",
    "\n",
    "\n",
    "#### Here's an quick summary of how to get started:\n",
    "  - Follow the installation instructions (for Windows, Mac or Linux).\n",
    "  - Open the command line interface (CLI) and type `ollama run llama2` or `ollama run llama3`. \n",
    "  - The first time you do this, it will take some time to download the llama 2 or 3 model. After that, you'll see \n",
    "> `>>> Send a message (/? for help)`\n",
    "\n",
    "- You can type your prompt and the llama-2 model on your computer will give you a response!\n",
    "- To exit, type `/bye`.\n",
    "- For a list of other commands, type `/?`.\n",
    "\n",
    "![](ollama_example.png \"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71958a71-89d9-4ccb-88e2-97fa173bb09e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
